{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vital Signs Anomaly Detection — ML Pipeline\n",
    "\n",
    "**Author:** Damir Zhumangali  \n",
    "**GitHub:** github.com/damirzhumangali  \n",
    "\n",
    "## Overview\n",
    "\n",
    "This project builds a machine learning pipeline for detecting anomalies in patient vital signs — extending the IoT-based Patient Health Monitoring System with intelligent data analysis.\n",
    "\n",
    "The pipeline covers:\n",
    "1. Data loading, cleaning, and exploratory analysis (Pandas, Matplotlib)\n",
    "2. Classical ML classifiers with comparison (scikit-learn)\n",
    "3. Unsupervised anomaly detection for unlabeled IoT streams (Isolation Forest)\n",
    "4. Deep learning time-series model (PyTorch LSTM)\n",
    "5. Rigorous validation with clinical metrics (ROC-AUC, precision-recall)\n",
    "\n",
    "**Dataset:** UCI Heart Disease Dataset (303 patients, 14 features)  \n",
    "**Task:** Binary classification — predict presence of heart disease\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once to install required packages\n",
    "# !pip install pandas numpy matplotlib seaborn scikit-learn torch torchvision ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Load UCI Heart Disease dataset\n",
    "heart_disease = fetch_ucirepo(id=45)\n",
    "\n",
    "X = heart_disease.data.features\n",
    "y = heart_disease.data.targets\n",
    "\n",
    "# Combine into single DataFrame for exploration\n",
    "df = X.copy()\n",
    "df['target'] = (y.values.ravel() > 0).astype(int)  # 0 = no disease, 1 = disease\n",
    "\n",
    "print('Dataset shape:', df.shape)\n",
    "print('\\nClass distribution:')\n",
    "print(df['target'].value_counts())\n",
    "print('\\nFirst 5 rows:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature descriptions\n",
    "feature_descriptions = {\n",
    "    'age': 'Age in years',\n",
    "    'sex': 'Sex (1=male, 0=female)',\n",
    "    'cp': 'Chest pain type (0-3)',\n",
    "    'trestbps': 'Resting blood pressure (mmHg)',\n",
    "    'chol': 'Serum cholesterol (mg/dl)',\n",
    "    'fbs': 'Fasting blood sugar > 120 mg/dl (1=true)',\n",
    "    'restecg': 'Resting ECG results (0-2)',\n",
    "    'thalach': 'Max heart rate achieved (BPM)',\n",
    "    'exang': 'Exercise-induced angina (1=yes)',\n",
    "    'oldpeak': 'ST depression induced by exercise',\n",
    "    'slope': 'Slope of peak exercise ST segment',\n",
    "    'ca': 'Number of major vessels (0-3)',\n",
    "    'thal': 'Thalassemia type',\n",
    "}\n",
    "\n",
    "print('Feature descriptions:')\n",
    "for feat, desc in feature_descriptions.items():\n",
    "    print(f'  {feat:12s} — {desc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print('Missing values:')\n",
    "print(df.isnull().sum())\n",
    "print('\\nData types:')\n",
    "print(df.dtypes)\n",
    "print('\\nStatistical summary:')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Vital Sign Distributions by Heart Disease Status', fontsize=14, fontweight='bold')\n",
    "\n",
    "key_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'cp']\n",
    "labels = ['Age', 'Resting BP (mmHg)', 'Cholesterol (mg/dl)', \n",
    "          'Max Heart Rate (BPM)', 'ST Depression', 'Chest Pain Type']\n",
    "\n",
    "for ax, feat, label in zip(axes.flat, key_features, labels):\n",
    "    for target_val, color, name in [(0, '#2196F3', 'No Disease'), (1, '#F44336', 'Heart Disease')]:\n",
    "        data = df[df['target'] == target_val][feat].dropna()\n",
    "        ax.hist(data, alpha=0.6, color=color, label=name, bins=20)\n",
    "    ax.set_title(label)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(feat)\n",
    "    ax.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('vital_signs_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: vital_signs_distribution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 9))\n",
    "corr_matrix = df.corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', \n",
    "            cmap='RdBu_r', center=0, square=True, linewidths=0.5,\n",
    "            cbar_kws={'shrink': 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "y_binary = (y.values.ravel() > 0).astype(int)\n",
    "\n",
    "# Train/test split — stratified to preserve class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y_binary, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_binary\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f'Training set: {X_train_scaled.shape[0]} samples')\n",
    "print(f'Test set:     {X_test_scaled.shape[0]} samples')\n",
    "print(f'\\nClass balance (train): {np.bincount(y_train)}')\n",
    "print(f'Class balance (test):  {np.bincount(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classical ML Classifiers — Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    roc_curve, precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest':       RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting':   GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM (RBF kernel)':    SVC(kernel='rbf', probability=True, random_state=42),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    y_prob = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': clf,\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob,\n",
    "        'roc_auc': roc_auc_score(y_test, y_prob),\n",
    "        'avg_precision': average_precision_score(y_test, y_prob),\n",
    "    }\n",
    "    \n",
    "    print(f'\\n── {name} ──')\n",
    "    print(classification_report(y_test, y_pred, target_names=['No Disease', 'Heart Disease']))\n",
    "    print(f'ROC-AUC: {results[name][\"roc_auc\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# ROC curve\n",
    "ax = axes[0]\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random baseline')\n",
    "for name, res in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, res['y_prob'])\n",
    "    ax.plot(fpr, tpr, label=f\"{name} (AUC={res['roc_auc']:.3f})\")\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves — Classifier Comparison')\n",
    "ax.legend(loc='lower right', fontsize=9)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Precision-Recall curve\n",
    "ax = axes[1]\n",
    "for name, res in results.items():\n",
    "    prec, rec, _ = precision_recall_curve(y_test, res['y_prob'])\n",
    "    ax.plot(rec, prec, label=f\"{name} (AP={res['avg_precision']:.3f})\")\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_title('Precision-Recall Curves')\n",
    "ax.legend(loc='lower left', fontsize=9)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Clinical Validation Metrics', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_pr_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Confusion Matrices', fontsize=13, fontweight='bold')\n",
    "\n",
    "for ax, (name, res) in zip(axes.flat, results.items()):\n",
    "    cm = confusion_matrix(y_test, res['y_pred'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['No Disease', 'Heart Disease'],\n",
    "                yticklabels=['No Disease', 'Heart Disease'])\n",
    "    ax.set_title(f'{name}\\nROC-AUC: {res[\"roc_auc\"]:.3f}')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_xlabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrices.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (Random Forest)\n",
    "rf = results['Random Forest']['model']\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "bars = plt.barh(importances.index, importances.values, color='#1F4E8A', alpha=0.8)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Random Forest — Feature Importance\\n(Which vital signs matter most?)', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Unsupervised Anomaly Detection\n",
    "\n",
    "In real IoT deployments, labeled anomalies are rare — sensors stream continuously and ground truth labels don't exist. This section demonstrates unsupervised anomaly detection using Isolation Forest, which identifies data points that are statistically \"isolated\" from the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Train Isolation Forest on HEALTHY patients only (unsupervised — no labels used)\n",
    "X_healthy = X_train_scaled[y_train == 0]\n",
    "\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination=0.1,  # expect ~10% anomalies\n",
    "    random_state=42\n",
    ")\n",
    "iso_forest.fit(X_healthy)\n",
    "\n",
    "# Predict on test set — (-1) = anomaly, (1) = normal\n",
    "iso_pred_raw = iso_forest.predict(X_test_scaled)\n",
    "iso_pred = (iso_pred_raw == -1).astype(int)  # convert to 0/1\n",
    "\n",
    "# Anomaly scores (lower = more anomalous)\n",
    "anomaly_scores = iso_forest.score_samples(X_test_scaled)\n",
    "\n",
    "print('Isolation Forest — Anomaly Detection Results')\n",
    "print('=' * 50)\n",
    "print(f'Detected anomalies: {iso_pred.sum()} / {len(iso_pred)}')\n",
    "print(f'\\nComparison with true disease labels:')\n",
    "print(classification_report(y_test, iso_pred, target_names=['Normal', 'Anomaly']))\n",
    "print(f'\\nNote: This model was trained WITHOUT labels — any performance')\n",
    "print(f'above random baseline demonstrates meaningful anomaly detection.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize anomaly scores\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Histogram of anomaly scores\n",
    "plt.subplot(1, 2, 1)\n",
    "for label, color, name in [(0, '#2196F3', 'No Disease'), (1, '#F44336', 'Heart Disease')]:\n",
    "    scores = anomaly_scores[y_test == label]\n",
    "    plt.hist(scores, alpha=0.6, bins=25, color=color, label=name)\n",
    "plt.axvline(x=iso_forest.threshold_, color='black', linestyle='--', label='Decision threshold')\n",
    "plt.xlabel('Anomaly Score (lower = more anomalous)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Isolation Forest\\nAnomaly Score Distribution')\n",
    "plt.legend()\n",
    "\n",
    "# 2D projection\n",
    "plt.subplot(1, 2, 2)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X_test_scaled)\n",
    "\n",
    "scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], \n",
    "                      c=anomaly_scores, cmap='RdYlGn',\n",
    "                      alpha=0.7, s=60)\n",
    "plt.colorbar(scatter, label='Anomaly Score')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "plt.title('PCA Projection\\n(Red = anomalous, Green = normal)')\n",
    "\n",
    "plt.suptitle('Unsupervised Anomaly Detection — Isolation Forest', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('anomaly_detection.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deep Learning — LSTM for Time-Series Vital Signs (PyTorch)\n",
    "\n",
    "LSTM networks are well-suited for sequential patient data — heart rate, SpO2, and temperature readings over time. Here we simulate a time-series scenario from the static dataset, then train a PyTorch LSTM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-series sequences from tabular data\n",
    "# Each \"patient\" becomes a sequence of 5 time steps with slight noise\n",
    "# (simulating repeated sensor readings)\n",
    "\n",
    "def create_sequences(X, y, seq_len=5, noise_std=0.05):\n",
    "    \"\"\"Convert static features to simulated time-series sequences.\"\"\"\n",
    "    sequences = []\n",
    "    for i in range(len(X)):\n",
    "        seq = []\n",
    "        for t in range(seq_len):\n",
    "            noise = np.random.normal(0, noise_std, X.shape[1])\n",
    "            seq.append(X[i] + noise)\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences, dtype=np.float32), np.array(y, dtype=np.float32)\n",
    "\n",
    "SEQ_LEN = 5\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, seq_len=SEQ_LEN)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test, seq_len=SEQ_LEN)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train_seq), torch.from_numpy(y_train_seq))\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test_seq), torch.from_numpy(y_test_seq))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f'Sequence shape: {X_train_seq.shape}  (samples, time_steps, features)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "class VitalSignsLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, dropout=0.3):\n",
    "        super(VitalSignsLSTM, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, features)\n",
    "        lstm_out, (hidden, _) = self.lstm(x)\n",
    "        # Use last hidden state for classification\n",
    "        last_hidden = hidden[-1]  # (batch, hidden_size)\n",
    "        output = self.classifier(last_hidden)\n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "INPUT_SIZE = X_train_scaled.shape[1]  # number of features\n",
    "model = VitalSignsLSTM(input_size=INPUT_SIZE).to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Model architecture:')\n",
    "print(model)\n",
    "print(f'\\nTotal trainable parameters: {total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # ── Train ──\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0.0, 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_correct += ((outputs > 0.5) == y_batch.bool()).sum().item()\n",
    "    \n",
    "    # ── Validate ──\n",
    "    model.eval()\n",
    "    val_loss, val_correct = 0.0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            val_correct += ((outputs > 0.5) == y_batch.bool()).sum().item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    val_losses.append(val_loss / len(test_loader))\n",
    "    train_accs.append(train_correct / len(y_train_seq))\n",
    "    val_accs.append(val_correct / len(y_test_seq))\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1:3d}/{EPOCHS}] '\n",
    "              f'Train Loss: {train_losses[-1]:.4f} | '\n",
    "              f'Val Loss: {val_losses[-1]:.4f} | '\n",
    "              f'Train Acc: {train_accs[-1]:.3f} | '\n",
    "              f'Val Acc: {val_accs[-1]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "ax1.plot(train_losses, label='Train Loss', color='#1F4E8A')\n",
    "ax1.plot(val_losses, label='Validation Loss', color='#F44336')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('BCE Loss')\n",
    "ax1.set_title('Training & Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2.plot(train_accs, label='Train Accuracy', color='#1F4E8A')\n",
    "ax2.plot(val_accs, label='Validation Accuracy', color='#F44336')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training & Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('LSTM Training Curves — Vital Signs Classification', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lstm_training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final LSTM evaluation\n",
    "model.eval()\n",
    "all_probs, all_preds = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, _ in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        probs = model(X_batch).cpu().numpy()\n",
    "        all_probs.extend(probs)\n",
    "        all_preds.extend((probs > 0.5).astype(int))\n",
    "\n",
    "lstm_auc = roc_auc_score(y_test, all_probs)\n",
    "print('LSTM Final Evaluation')\n",
    "print('=' * 50)\n",
    "print(classification_report(y_test, all_preds, target_names=['No Disease', 'Heart Disease']))\n",
    "print(f'ROC-AUC: {lstm_auc:.4f}')\n",
    "\n",
    "# Add LSTM to results for final comparison\n",
    "results['LSTM (PyTorch)'] = {\n",
    "    'y_pred': all_preds,\n",
    "    'y_prob': all_probs,\n",
    "    'roc_auc': lstm_auc,\n",
    "    'avg_precision': average_precision_score(y_test, all_probs),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Comparison & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "summary_rows = []\n",
    "for name, res in results.items():\n",
    "    cm = confusion_matrix(y_test, res['y_pred'])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)  # recall for disease class — critical in clinical settings\n",
    "    specificity = tn / (tn + fp)\n",
    "    summary_rows.append({\n",
    "        'Model': name,\n",
    "        'ROC-AUC': f\"{res['roc_auc']:.4f}\",\n",
    "        'Avg Precision': f\"{res['avg_precision']:.4f}\",\n",
    "        'Sensitivity': f\"{sensitivity:.4f}\",\n",
    "        'Specificity': f\"{specificity:.4f}\",\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows).set_index('Model')\n",
    "print('=' * 70)\n",
    "print('FINAL MODEL COMPARISON')\n",
    "print('=' * 70)\n",
    "print(summary_df.to_string())\n",
    "print('\\nNote: In clinical settings, Sensitivity (true positive rate) is')\n",
    "print('often prioritized — missing a disease case is more costly than a false alarm.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final ROC comparison including LSTM\n",
    "plt.figure(figsize=(9, 7))\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.4, label='Random baseline')\n",
    "\n",
    "colors = ['#1F4E8A', '#E53935', '#2E7D32', '#F57F17', '#6A1B9A']\n",
    "for (name, res), color in zip(results.items(), colors):\n",
    "    fpr, tpr, _ = roc_curve(y_test, res['y_prob'])\n",
    "    plt.plot(fpr, tpr, color=color, linewidth=2,\n",
    "             label=f\"{name} (AUC={res['roc_auc']:.3f})\")\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
    "plt.title('ROC Curves — All Models\\n(Vital Signs Anomaly Detection)', fontsize=13, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_roc_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nAll figures saved to current directory.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Findings & Next Steps\n",
    "\n",
    "### What this project demonstrates\n",
    "- Full ML pipeline from raw biomedical data to validated clinical models\n",
    "- Comparison of classical (sklearn) and deep learning (PyTorch) approaches\n",
    "- Unsupervised anomaly detection for real-world IoT scenarios without labeled data\n",
    "- Clinical validation metrics — sensitivity, specificity, ROC-AUC, precision-recall\n",
    "\n",
    "### Key insight\n",
    "In clinical settings, model validation is not just about accuracy — **sensitivity** (not missing disease cases) must be weighted differently than specificity. This tradeoff is central to Dr. Ayhan's research on rigorous clinical AI validation.\n",
    "\n",
    "### Connection to IoT pipeline\n",
    "The Patient Health Monitoring System collects real-time ESP32 sensor data. This ML pipeline is the next layer — replacing threshold-based anomaly detection with learned models that adapt to patient-specific baselines.\n",
    "\n",
    "### Next steps\n",
    "1. **Real sensor data** — replace UCI dataset with actual ESP32 readings from Patient_Health_Monitoring\n",
    "2. **Personalized baselines** — train per-patient models to detect deviations from individual normal ranges\n",
    "3. **Real-time inference** — deploy model on Raspberry Pi 4 for edge inference without cloud dependency\n",
    "4. **Federated learning** — train across multiple patient devices without centralizing sensitive data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
